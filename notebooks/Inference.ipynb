{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":282989,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":242487,"modelId":264116}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom transformers import BertTokenizer\n\n# Load the tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n# Load the TensorFlow model from the .h5 file\nMODEL_PATH = \"/kaggle/input/bertmodel/tensorflow2/default/1/multi_task_bert_model.h5\"\ncustom_objects = {'TFBertModel': TFBertModel}  # Register custom layer\nwith tf.keras.utils.custom_object_scope(custom_objects):\n    model = tf.keras.models.load_model(MODEL_PATH)\n\n# Define a function for inference\ndef predict_sentiment(text):\n    \"\"\"\n    Predicts the sentiment and rank score for a given input text.\n    \"\"\"\n    # Tokenize the input text\n    inputs = tokenizer(\n        text, \n        max_length=128, \n        truncation=True, \n        padding='max_length', \n        return_tensors='tf',\n        return_token_type_ids=False  # Disable token_type_ids\n    )\n    \n    # Perform inference\n    outputs = model([inputs['input_ids'], inputs['attention_mask']])\n    \n    # Inspect the outputs structure\n    print(\"Outputs:\", outputs)\n    \n    # Extract the sentiment score (regression output)\n    sentiment_score = outputs[0].numpy()[0][0]  # Assuming sentiment_score is the first output\n    \n    # Map the sentiment score to a label\n    sentiment_label = \"POSITIVE\" if sentiment_score > 0.5 else \"NEGATIVE\"\n    \n    # Get the rank score (if your model outputs it)\n    if len(outputs) > 1:  # Assuming rank_score is the second element in outputs\n        rank_score = outputs[1].numpy()[0][0]\n    else:\n        rank_score = None\n    \n    return {\n        \"text\": text,\n        \"sentiment\": sentiment_label,\n        \"sentiment_score\": float(sentiment_score),\n        \"rank_score\": float(rank_score) if rank_score is not None else None\n    }\n\n# Test the model with some example text\nexample_text = \"The company reported strong earnings and a record high stock price.\"\nresult = predict_sentiment(example_text)\n\n# Print the result\nprint(\"Input Text:\", result[\"text\"])\nprint(\"Sentiment:\", result[\"sentiment\"])\nprint(\"Sentiment Score:\", result[\"sentiment_score\"])\nprint(\"Rank Score:\", result[\"rank_score\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T23:17:48.864944Z","iopub.execute_input":"2025-03-11T23:17:48.865387Z","iopub.status.idle":"2025-03-11T23:17:58.512717Z","shell.execute_reply.started":"2025-03-11T23:17:48.865354Z","shell.execute_reply":"2025-03-11T23:17:58.511649Z"}},"outputs":[{"name":"stdout","text":"Outputs: [<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.97613424]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[4.7709417]], dtype=float32)>]\nInput Text: The company reported strong earnings and a record high stock price.\nSentiment: POSITIVE\nSentiment Score: 0.9761342406272888\nRank Score: 4.770941734313965\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}